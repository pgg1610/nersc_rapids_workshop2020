{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP: What is it and how cuML helps\n",
    "\n",
    "[UMAP](https://umap-learn.readthedocs.io/en/latest/) is a powerful, non-linear dimensionality reduction tool which NVIDIA recently ported to GPUs. Besides dimensionality reduction it can be used for powerful dataset visualizations, which is what we will use if for.\n",
    "\n",
    "In this notebook we will demostrate basic usage, plotting, and timing of the unsupervised cuML version of UMAP. We will compare the visual results to t-sne and also the runtime characteristics to UMAP-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets begin by importing our needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# libraries for scoring/clustering\n",
    "from cuml.metrics import trustworthiness\n",
    "\n",
    "#CPU UMAP\n",
    "import umap\n",
    "\n",
    "# GPU UMAP\n",
    "import cudf\n",
    "from cuml.manifold.umap import UMAP as cumlUMAP\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# sns.set(style='white', rc={'figure.figsize':(25, 12.5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to ignore some warnings irrelevant to the tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide warnings\n",
    "import warnings\n",
    "from numba.errors import NumbaWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=NumbaWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks\n",
    "\n",
    "It is a good practice to check for the needed files or hardware before spending time processing things.\n",
    "\n",
    "We are going to work with 2 MNIST datasets: digits and fashion.  This datasets consisting of 70,000 28x28 grayscale images of clothing and handwritten digits.  They should already be in the `data` folder, but let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/fashion') and not os.path.exists('../data/digits'):\n",
    "    print(\"error, data is missing!\")\n",
    "    \n",
    "FASHION_PATH = '../data/fashion'\n",
    "DIGITS_PATH = '../data/digits/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure we have our RAPIDS compliant GPU.  It must be Pascal or higher, that means 10 series, 20 series or a Quadro Pascal, Volta or Turing card.  You can also use this to define which GPU RAPIDS should use (advanced feature not covered here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output also tells you information about utilization of the GPUs, so if you have been following the tutorials you probably see processes from the other notebooks, we **highly** recommend stopping those notebooks to free up resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of UMAP for MNIST digits dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function to load data\n",
    "\n",
    "We have provided a nice utility function to quickly load the MNIST datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_labels = load_mnist(DIGITS_PATH, kind='train')\n",
    "test, test_labels = load_mnist(DIGITS_PATH, kind='t10k')\n",
    "data = np.array(np.vstack([train, test]), dtype=np.float64)\n",
    "target = np.array(np.hstack([train_labels, test_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 784 images, we can see how our dataset looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Train shape: {train.shape} and Test Shape: {test.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how a single image looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a 5\n",
    "pixels = train[0].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One algorithm that has been used in the past to succesfully visualize this dataset it t-sne:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/digitstsne.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph was generated with a beta version of cuML's t-sne implementation (see https://github.com/rapidsai/cuml/pull/682). It manages to separate the digits pretty cleanly so it works well as a baseline case to see how UMAP behaves now!\n",
    "\n",
    "First lets use the CPU based UMAP-learn, **note that it might take more than a minute to process**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# CPU UMAP: using umap-learn package\n",
    "cpu_umap = umap.UMAP(n_neighbors=5, init=\"spectral\").fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that instead of creating the class first, then using `fit` to train the model and then `transform` to transform the data to reduce the dimensionality, we did that in a single line. \n",
    "\n",
    "The relevant parameters used for the algorithm are: \n",
    "\n",
    "```\n",
    "n_neighbors:  number of neighboring points used in local approximations of manifold structure. It controls how well high level details are conserved against low level details of the geometric structure of the data. Values of 5 to 20 are typical.\n",
    "\n",
    "init: Strategy to choose the initial embedding to start the algorithm in, `spectral` usually will lead to better results but is newer than `random`.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try the cuML GPU version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = cudf.DataFrame()\n",
    "for i in range(data.shape[1]):\n",
    "    data_df['fea%d'%i] = data[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gpu_umap = cumlUMAP(n_neighbors=5, init=\"spectral\").fit_transform(data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets visualize the results! First lets name the classes appropriately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    '0',\n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "    '5',\n",
    "    '6',\n",
    "    '7',\n",
    "    '8',\n",
    "    '9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gpu_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_embedding_numpy = gpu_umap.as_matrix() # it is necessary to convert to numpy array to do the visual mapping\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(g_embedding_numpy[:,1], g_embedding_numpy[:,0], s=0.3, c=target, cmap='Spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = plt.colorbar(boundaries=np.arange(11)-0.5)\n",
    "cbar.set_ticks(np.arange(10))\n",
    "cbar.set_ticklabels(classes)\n",
    "plt.title('Fashion MNIST Embedded via cumlUMAP');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Use UMAP to visualize the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see how t-sne behaves with the fashion dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/fashiontsne.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the result here is not as clean as for the digits dataset. Therefore lets use UMAP to see if we can improve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_labels = load_mnist(FASHION_PATH, kind='train')\n",
    "test, test_labels = load_mnist(FASHION_PATH, kind='t10k')\n",
    "data = np.array(np.vstack([train, test]), dtype=np.float64) / 255\n",
    "target = np.array(np.hstack([train_labels, test_labels]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60000 training images and 10000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"Train shape: {train.shape} and Test Shape: {test.shape}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, each row in the train matrix is an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display a sneaker\n",
    "pixels = train[0].reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now its your turn to train the UMAP models:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "OK, now let's plot the output of the embeddings so that we can see the seperation of the neighborhoods.  Let's start by creating the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    'T-shirt/top',\n",
    "    'Trouser',\n",
    "    'Pullover',\n",
    "    'Dress',\n",
    "    'Coat',\n",
    "    'Sandal',\n",
    "    'Shirt',\n",
    "    'Sneaker',\n",
    "    'Bag',\n",
    "    'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now its your turn to visualize the dataset in a similar manner to the digits one**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we can also quantitatively compare the perfomance of `cumlUMAP` (GPU UMAP) to the reference/original implementation (CPU UMAP) using the [trustworthiness score](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L395).  From the docstring:\n",
    "\n",
    "> Trustworthiness expresses to what extent the local structure is retained.  The trustworthiness is within [0, 1].\n",
    "\n",
    "\n",
    "Like `t-SNE`, UMAP tries to capture both global and local structure and thus, we can apply the `trustworthiness` of the `g_embedding` data against the original input.  With a higher score we are demonstrating that the algorithm does a better and better job of local structure retention. Algorithms like UMAP aim to preserve local neighborhood structure and so measuring this property (trustworthiness) measures the algorithm's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: sklearn trustworthiness calculation can run out of memory in the instance!\n",
    "# trust = trustworthiness(data, cpu_umap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring ~97% shows the GPU implementation is comparable to the original CPU implementation!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
